{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_date(train_val_test_dates=[None, None, None],\n",
    "                 extra_features=None,\n",
    "                 only_normal_shops=False,\n",
    "                 only_normal_items=False):\n",
    "    \"\"\"\n",
    "    Prepares the data in \"train_clean.csv\" for xgboost, with options for feature engineering and other manipulation.\n",
    "\n",
    "    Args:\n",
    "        train_val_test_dates: 'YYYY-MM-DD' format, specify train start date, val start date, test start date.\n",
    "        extra_features=None: if True, item_category and an assortment of time-based features are added\n",
    "        only_normal_shops=False: some shops are not present in \"test.csv\" and tend to have unusual distributions. if True, exclude these.\n",
    "        only_normal_items=False: some items are not present in \"test.csv\". if True, exclude these.\n",
    "\n",
    "    Returns:\n",
    "        dtrain, dvalidation, dtest, train, validation, test, df\n",
    "    \"\"\"\n",
    "    def only_normal(df, shops=False, items=False):\n",
    "        \"\"\"\n",
    "        Returns df with only shops, items found in \"test.csv\" depending on if shops, items = True is set (defaults: False). mutates df.\n",
    "        \"\"\"\n",
    "        normal = pd.read_csv('test.csv')\n",
    "\n",
    "        # if enabled, only items and/or shops in 'test.csv' are retained in self.df\n",
    "        if shops:\n",
    "            normal_shops = normal['shop_id'].unique()\n",
    "            df = df[df['shop_id'].isin(normal_shops)]\n",
    "        if items:\n",
    "            normal_items = normal['item_id'].unique()\n",
    "            df = df[df['item_id'].isin(normal_items)]\n",
    "        return df\n",
    "\n",
    "    def add_features(df):\n",
    "        \"\"\"\n",
    "        Add item categories to df and assorted date features. Mutates df.\n",
    "\n",
    "        Returns: df\n",
    "        \"\"\"\n",
    "        # get items csv and use id and categories columns as key to add item categories to dataframe\n",
    "        df['item_category_id'] = df['item_id'].map(items.set_index('item_id')['item_category_id'])\n",
    "\n",
    "        # add some time features, add the dates as a column to do this, remove date column at the end\n",
    "        df['date'] = df.index\n",
    "        df['dayofweek'] = df['date'].dt.dayofweek\n",
    "        df['month'] = df['date'].dt.month\n",
    "        df['year'] = df['date'].dt.year\n",
    "        df['dayofyear'] = df['date'].dt.dayofyear\n",
    "        df['dayofmonth'] = df['date'].dt.day\n",
    "\n",
    "        df.drop(columns='date', inplace=True)\n",
    "        return df\n",
    "\n",
    "    def train_val_test_split(df, train_val_test_dates):\n",
    "        \"\"\"\n",
    "        Returns train, val, test split of df, as dataframes including labels, according to date splits. Does not mutate df.\n",
    "\n",
    "        Format: 'YYYY-MM-DD'\n",
    "        \"\"\"\n",
    "        train_start_date, validation_start_date, test_start_date = train_val_test_dates[0], train_val_test_dates[1], train_val_test_dates[2]\n",
    "\n",
    "        train = df[(train_start_date <= df.index) & df.index < val_start_date].copy()\n",
    "        validation = df[(val_start_date <= df.index) & (df.index < test_start_date)].copy()\n",
    "        test = df[test_start_date <= df.index].copy()\n",
    "\n",
    "        return train, validation, test\n",
    "\n",
    "    def make_dmatrix(df):\n",
    "        \"\"\"\n",
    "        Convert pandas dataframe to DMatrix for xgboost, splitting off labels and including in dmatrix as need. Does not mutate df.\n",
    "        \"\"\"\n",
    "        X = dataframe.copy()\n",
    "        y = X.pop('item_cnt_day')\n",
    "        dmatrix = xgb.DMatrix(X, label=y)\n",
    "        return dmatrix\n",
    "\n",
    "    # import and use dates as index, sort by date\n",
    "    df = pd.read_csv(\"train_clean.csv\", index_col=[0], parse_dates=[0], dayfirst=True)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # if True, use only shops and/or items found in \"test.csv\"\n",
    "    if only_normal_shops:\n",
    "        df = only_normal(df, shops=True)\n",
    "    if only_normal_items:\n",
    "        df = only_normal(df, items=True)\n",
    "\n",
    "    # if True, add item category and various time features\n",
    "    if extra_features:\n",
    "        df = add_features(df)\n",
    "\n",
    "    train, validation, test = train_val_test_split(df, train_val_test_dates)\n",
    "\n",
    "    # dmatrices for xgboost\n",
    "    dtrain, dvalidation, dtest = make_dmatrix(train), make_dmatrix(validation), make_dmatrix(test)\n",
    "\n",
    "    return dtrain, dvalidation, dtest, train, validation, test, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2nd to last month (sep 2015) as validation\n",
    "# last month (oct 2015) as test\n",
    "val_start_date, test_start_date = '2015-09-01', '2015-10-01'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.groupby('date').item_cnt_day.mean().plot(figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# might also want to use mean\n",
    "validation['item_cnt_day'].groupby('date').sum().plot(figsize=(20, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make model\n",
    "def make_model():\n",
    "    params = {}\n",
    "    params['eval_metric'] = ['mae', 'mape', 'rmse'] # last metric is used for early stopping\n",
    "    params['nthread'] = 4\n",
    "    params['eta'] = .3 # learning rate, default = 0.3\n",
    "    params['max_depth'] = 6 # default = 6\n",
    "\n",
    "    # gpu (needs CUDA compute >= 3.5)\n",
    "    # params['gpu_id'] = 0\n",
    "    # params['tree_method'] = 'gpu_hist'\n",
    "\n",
    "    # track performance on this data\n",
    "    evallist = [(dvalidation, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "    num_boost_round = 200 # how many trees, default = 10\n",
    "    early_stopping_rounds = 10\n",
    "\n",
    "    model = xgb.train(params=params,\n",
    "                    dtrain=dtrain,\n",
    "                    num_boost_round=num_boost_round,\n",
    "                    evals=evallist,\n",
    "                    early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict using the best iteration's values\n",
    "val_predictions = model.predict(dvalidation, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "# pd.DataFrame(data=val_predictions, index=validation.index, columns=['item_cnt_pred']).groupby('date').sum().plot(figsize=(20, 5))\n",
    "\n",
    "# this isn't so bad! the real surprise is why adding time features doesn't seem to make a difference...\n",
    "val_compare = pd.DataFrame(data=val_predictions, index=validation.index, columns=['item_cnt_pred'])\n",
    "val_compare['item_cnt_day'] = validation['item_cnt_day']\n",
    "val_compare.groupby('date').sum().plot(figsize=(20, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "xgboost.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
