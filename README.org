# title shouldn't appear in toc
* Kaggle Predict Sales :noexport:

This notebook implements an XGBoost model to forecast various item sales at various stores in Russia, based on 3 years of sales data. The data is taken from this [[https://www.kaggle.com/c/competitive-data-science-predict-future-sales/overview][kaggle competition]] (which has a slightly different objective).

* Contents :TOC:
- [[#data--eda][Data + EDA]]
  - [[#data][Data]]
  - [[#eda][EDA]]
- [[#results][Results]]
  - [[#summary][Summary]]
  - [[#baseline-model][Baseline model]]
  - [[#add-item-categories-and-various-time-features][Add item categories and various time features]]
  - [[#use-only-the-most-recent-years-data][Use only the most recent year's data]]
- [[#possible-improvements][Possible improvements]]
  - [[#improve-these-models][Improve these models]]
  - [[#multi-step-prediction][Multi-step prediction]]
  - [[#other-models][Other models]]
- [[#files-in-this-repository][Files in this Repository]]

* Data + EDA

** Data

Data available [[https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data][here]]. Data gives count of sales of various items at various shops in Russia, across a 3 year period. Our goal is to predict item sales at these stores in future months.

** EDA

See eda.ipynb . Summarizing:

- There are a small number of duplicate rows. We remove these in cleaning.
- No missing values.
- dtypes are all float and int, once we convert dates to datetime object and use as index.
- Checking feature histograms:

[[feature_hist.png]]

- Some shops have significantly more entries than others, some item categories appear significantly more often than others
- Low prices and low item sale counts appear much more often than higher values.
- We see spikes in number of entries each year in December.
- There is a single entry with negative item price - we remove this in cleaning.
- There are many negative item sales counts. Perhaps these are returns - we don't remove these.
- There is one item that is an extreme outlier in price and was only bought once ever. It appears to be some sort of corporate software. We remove this outlier.
- There are some outliers in total item sales in one day. We don't know enough to remove these.
- There are shops and items that have noticeably strange behavior, such as much fewer sales in the most recent year. We identify these as shops and items not asked for in the test.csv file. We use these entries in our baseline model, but remove them in our subsequent models when we begin feature engineering.

* Results
** Summary

- Trained 3 models with xgboost: baseline, adding item category and various time features, and feature engineering + using only the most recent year's data (perhaps using only recent data improves performance).
- Last month of data used as test set, 2nd to last month used as validation set.
- Models were trained with default parameters, except for training with as many trees as need until overfitting (as measured by RSME on validation set).
- Models were evaluated using RSME. MAE and MAPE were also tracked, but in general these are poor metrics for this task: almost all item count values are 1 and so if the model makes even a slight error such as predicting 2 instead of 1, this is 100% error according to MAPE.
- The model using all of the data + feature engineering performed best. The baseline model immediately overfit, showing poor generalization to validation. The model using feature engineering + only the most recent year's data performed slightly worse on the test set than the model using all of the data.
- Even the best model had RMSE of roughly 10 on the test set. This isn't terrible, but is noticeably worse than the validation set (roughly 1.5). It could be that the majority of this error is coming from a single day in late October 2015 (see plots in subsequent sections). Googling Russian holidays didn't turn up anything obvious to explain this.
- Difficult to get an overall visualization of the prediction for count of sales for so many item-shop combinations. As a rough test, we plot predicted total sales and the true values for total sales on each day of the predicted month. We see decent qualitative agreement.

** Baseline model

Observations:

- Validation RMSE always much higher than train, overfitting/model not very predictive.
- Decent looking summarising graphs for validation and test.

Summary Statistics:

number of trees: 20

train-rmse: 1.80402	
validation-rmse: 6.08256

train-mape: 0.20434	
validation-mape: 0.17836

train-mae: 0.34221	
validation-mae: 0.50230

test rsme: 9.379496907843956

[[baseline_feature_importance.png]]

[[baseline_validation.png]]

[[baseline_test.png]]

** Add item categories and various time features

Observations:

- Excellent improvement in rmse on validation over baseline model.
- Not great rmse on test (not terrible).
- Otherwise, decent looking summarising graphs for validation and test.

Summary Statistics

number of trees: 98

train-rmse: 1.56050	
validation-rmse: 1.56527

train-mape: 0.21753	
validation-mape: 0.22912

train-mae: 0.36448	
validation-mae: 0.39369

test rsme: 9.754962031326457

[[add_features_feature_importance.png]]

[[add_features_validation.png]]

[[add_features_test.png]]

** Use only the most recent year's data

Observations:

- No major difference from using all of the data.
- If anything, RMSE on test worsens using only data from 2015.

Summary statistics:

number of trees: 39

train-rmse: 1.47490		
validation-rmse: 1.47621

train-mape: 0.17846	
validation-mape: 0.17519

train-mae: 0.29268	
validation-mae: 0.34397

test rmse: 10.024865745802856

[[add_features_2015_feature_importance.png]]

[[add_features_2015_validation.png]]

[[add_features_2015_test.png]]

* Possible improvements

Ran out of time, but here are some ways to improve:

** Improve these models
- Hyperparameter searches
- Look at days/items/shops where model performs worst for clues
- Add lag features
- Could see if making the data stationary helps
 
** Multi-step prediction
- We've done direct one-month ahead and two-month ahead prediction. Model can be adapted to direct N-month ahead predictions.
- Could try recursive N-month or N-day ahead predictions with this model.

** Other models
- ARIMA (maybe with just a few month's data)
- Prophet
- If time + compute, TFT looks cool and could be SOTA (as of 2020): https://arxiv.org/pdf/1912.09363v2.pdf
 
* Files in this Repository

- eda.ipynb
- clean_data.py

Run clean_data.py to create train_clean.csv, used in xgboost.ipynb  
  
- xgboost.ipynb
